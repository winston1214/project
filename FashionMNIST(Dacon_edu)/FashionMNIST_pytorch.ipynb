{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25321,
     "status": "ok",
     "timestamp": 1629201543306,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "PpvZZJRJqID7",
    "outputId": "15877029-d06b-4736-8e80-b4cb24f9d577"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1629201557288,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "PxsvLAI_-TBt"
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/MyDrive/딥러닝홀로서기')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4514,
     "status": "ok",
     "timestamp": 1629204186603,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "TnXa-fR_ItC2",
    "outputId": "9d141284-04c4-4dfd-adfe-4a8d6bc6e847"
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1629204209573,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "bKEm9hJEtDs4",
    "outputId": "cdd49a12-d0dd-4a15-e52b-93f2f08ccbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 9733,
     "status": "ok",
     "timestamp": 1629201569472,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "L9tm2kSQq_QM"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1629201569472,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "V1SR6zPSrRAa"
   },
   "outputs": [],
   "source": [
    "class FashionMNIST(D.Dataset):\n",
    "    def __init__(self,data,label,transform=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        image = self.data[idx]\n",
    "        image = image.reshape(-1, 28, 28).astype('float32')\n",
    "        label = self.label[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.transpose(0,1)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1629204788549,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "1ipKLdzGEjxF"
   },
   "outputs": [],
   "source": [
    "class PretrainModel(nn.Module):\n",
    "    def __init__(self,pretrained):\n",
    "        super().__init__()\n",
    "        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\n",
    "        self.pretrained = pretrained\n",
    "#         self.pretrained_fc = nn.Linear(1000,512)\n",
    "#         self.dropout = nn.Dropout(p = 0.3)\n",
    "#         self.activation = nn.SiLU()\n",
    "        self.FC = nn.Linear(1000,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.pretrained(x)\n",
    "#         x = self.pretrained_fc(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.activation(x)\n",
    "        x = self.FC(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1629201569473,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "U7y9nhxry5Ms"
   },
   "outputs": [],
   "source": [
    "# class FashionCNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(FashionCNN, self).__init__()\n",
    "        \n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         )\n",
    "        \n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2)\n",
    "#         )\n",
    "        \n",
    "#         self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "#         self.drop = nn.Dropout2d(0.25)\n",
    "#         self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "#         self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.layer1(x)\n",
    "#         out = self.layer2(out)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.drop(out)\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.fc3(out)\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.1307,), (0.3081,)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomAffine(30)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1356,
     "status": "ok",
     "timestamp": 1629205806937,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "-vD70-fJtRQc",
    "outputId": "a77eaac9-94ac-46d5-a7ad-1e4def331ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "pixel = train.to_numpy()[:,2:]\n",
    "labels = train.to_numpy()[:,1]\n",
    "BATCH_SIZE = 64\n",
    "# mobilenet_v3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "pretrained = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "model = PretrainModel(pretrained)\n",
    "# model = nn.DataParallel(FashionCNN())\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 1e-3)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2, eta_min=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1629205808312,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "ZHUDyiC3uZP2"
   },
   "outputs": [],
   "source": [
    "dataset = FashionMNIST(pixel,labels,transformer)\n",
    "train_dataset, val_dataset = D.random_split(dataset, [len(dataset) - int(len(dataset) * 0.1), int(len(dataset) * 0.1)])\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size = BATCH_SIZE,shuffle=True, drop_last = True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size = BATCH_SIZE, shuffle=True,drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnh_lQ89vFv_",
    "outputId": "75f761e2-e60c-43d3-ccc5-0a2982362d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [02:35,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [843/843], Loss: 1.0709359354537293, Acc 61.72709074733096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 55.42674731182796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [02:33,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [843/843], Loss: 0.9630886514274534, Acc 65.71211447212337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 68.07795698924731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [02:34,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [843/843], Loss: 0.8833972092625085, Acc 68.703662514828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 69.30443548387096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [02:34,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [843/843], Loss: 0.7885638726422229, Acc 72.31983985765125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 71.99260752688173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "209it [00:38,  5.39it/s]"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dataloader)\n",
    "batch_val_acc = 0\n",
    "EPOCH = 50\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train_acc_list = []\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for i,(images,labels) in tqdm(enumerate(train_dataloader)):\n",
    "        images = images.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        probs = model(images)\n",
    "\n",
    "        loss = criterion(probs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        probs = probs.cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        preds = np.argmax(probs,1)\n",
    "        # print(probs)\n",
    "        # print((preds == labels))\n",
    "        batch_acc =  (preds == labels).sum() / BATCH_SIZE * 100\n",
    "        train_acc_list.append(batch_acc)\n",
    "    \n",
    "    train_acc = np.mean(train_acc_list)\n",
    "    print(f'Epoch [{epoch+1}/{EPOCH}], Step [{i+1}/{total_step}], Loss: {running_loss/total_step}, Acc {train_acc}')\n",
    "\n",
    "    model.eval()\n",
    "    valid_acc_list = []\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.type(torch.FloatTensor).to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "            probs = model(images)\n",
    "            valid_loss = criterion(probs, labels)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            preds = np.argmax(probs,1)\n",
    "            batch_acc =  (preds == labels).sum() / BATCH_SIZE * 100\n",
    "            valid_acc_list.append(batch_acc)\n",
    "            \n",
    "        val_acc = np.mean(valid_acc_list)\n",
    "        print(f'Validation acc: {val_acc}')\n",
    "\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1629202812514,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "5XRplpeLALpX"
   },
   "outputs": [],
   "source": [
    "pixel = test.to_numpy()[:,1:]\n",
    "labels = submission.to_numpy()[:,1] # 의미 X\n",
    "test_dataset = FashionMNIST(pixel,labels)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8768,
     "status": "ok",
     "timestamp": 1629202823876,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "WxyUUhLk_8Rk",
    "outputId": "a9615045-4258-47f5-922e-0df45f758e62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:23<00:00, 22.57it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predict_list = []\n",
    "with torch.no_grad():\n",
    "    for images,labels in tqdm(test_dataloader):\n",
    "        images = images.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "        probs = model(images)\n",
    "        probs  = probs.cpu().detach().numpy()\n",
    "        preds = np.argmax(probs,1)\n",
    "        predict_list.append(preds[0].astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1629202823876,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "egWeKUH3-SAC"
   },
   "outputs": [],
   "source": [
    "submission['label'] = predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1629202825600,
     "user": {
      "displayName": "김영민",
      "photoUrl": "",
      "userId": "04915862517565535031"
     },
     "user_tz": -540
    },
    "id": "tZT1PSzI-SAC"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('eff-b7_transform.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
