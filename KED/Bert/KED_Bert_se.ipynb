{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KED_Bert_se.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"273710b949a44087845d1c56317d52c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_588132f4535d40d78b3b3d0912aadf78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_659086d9dc5841468b967ff624d199ee","IPY_MODEL_d3bf51b4ac424835947a7485169a2043"]}},"588132f4535d40d78b3b3d0912aadf78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"659086d9dc5841468b967ff624d199ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db374998a2ba4538b99011cd71414828","_dom_classes":[],"description":" 49%","_model_name":"FloatProgressModel","bar_style":"danger","max":23391,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":11476,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1456fff2e8e04852b169f33b09f77c63"}},"d3bf51b4ac424835947a7485169a2043":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57022b2abe59490c969e8ed19d07d9f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 11476/23391 [14:48:05&lt;17:07:46,  5.18s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6a877e499924dc5b30f98e60594e67e"}},"db374998a2ba4538b99011cd71414828":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1456fff2e8e04852b169f33b09f77c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57022b2abe59490c969e8ed19d07d9f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6a877e499924dc5b30f98e60594e67e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnDh2dZADgC5","executionInfo":{"status":"ok","timestamp":1621603808496,"user_tz":-540,"elapsed":35172,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"79c187e5-4f6b-4023-e235-3428e252344d"},"source":["!pip install mxnet\n","!pip install gluonnlp\n","!pip install sentencepiece\n","!pip install transformers==3\n","!pip install torch\n","\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mxnet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n","\u001b[K     |████████████████████████████████| 46.9MB 108kB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Installing collected packages: graphviz, mxnet\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n","Collecting gluonnlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n","\u001b[K     |████████████████████████████████| 348kB 10.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595683 sha256=4f327afd805cd750c0f26bd175b84fbc43331030c7d36fbf39410ae84cb40f9e\n","  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 9.2MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n","Collecting transformers==3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.95)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 19.6MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (8.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.8.0rc4 transformers-3.0.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-uh1o7rjd\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-uh1o7rjd\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12708 sha256=215e114089436b870f8603232cea4b7fb37af22ad9ccc6bca5103bd331da3890\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rjvm14_o/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n","Successfully built kobert\n","Installing collected packages: kobert\n","Successfully installed kobert-0.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Emq-odr1DoIp"},"source":["import pandas as pd\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnetO85tDoKy","executionInfo":{"status":"ok","timestamp":1621603836474,"user_tz":-540,"elapsed":20759,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"ccc996ce-a535-4c8c-cb55-8cc762920f66"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VShBaMquDoNS","executionInfo":{"status":"ok","timestamp":1621603867494,"user_tz":-540,"elapsed":51768,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"d093e97b-7087-4aab-ce98-6fc684582b7b"},"source":["device = torch.device(\"cuda:0\")\n","\n","bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[██████████████████████████████████████████████████]\n","[██████████████████████████████████████████████████]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oCboTTgDoTG"},"source":["dataset_train = nlp.data.TSVDataset('/content/drive/MyDrive/애쓰는 감자/data/new_data/train_plus_se_1.txt', field_indices=[1,2], num_discard_samples=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyxEdgTo6z4k"},"source":["# dataset_train = nlp.data.TSVDataset('/content/drive/MyDrive/애쓰는 감자/data/new_data/train_plus_se_2.txt', field_indices=[1,2], num_discard_samples=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRiOrnNUFwtN"},"source":["dataset_val = nlp.data.TSVDataset('/content/drive/MyDrive/애쓰는 감자/data/new_data/val_se.txt', field_indices=[1,2], num_discard_samples=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqxgsdE2DoVu","executionInfo":{"status":"ok","timestamp":1621603881118,"user_tz":-540,"elapsed":65366,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"d4c56e14-ce83-4f83-cf21-d4dde9c81653"},"source":["tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["using cached model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YnxPSTQJDoYG"},"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8nhHFEHD_u_"},"source":["max_len = 256 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n","batch_size = 24\n","warmup_ratio = 0.1\n","num_epochs = 2\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate = 5e-5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfOb5QyqEBQ4"},"source":["data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_val = BERTDataset(dataset_val, 0, 1, tok, max_len, True, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXIZpoMBEET5","executionInfo":{"status":"ok","timestamp":1621604288920,"user_tz":-540,"elapsed":473138,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"4682c419-c314-4efd-82a5-52ec6c5522c6"},"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","val_dataloader = torch.utils.data.DataLoader(data_val, batch_size=batch_size, num_workers=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FW6EfPEbEG_h"},"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes = 491, # softmax 사용 <- binary일 경우는 2\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIlBOHA9EI8R"},"source":["model = BERTClassifier(bertmodel, dr_rate=0.2).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWRdgxIgEKhp"},"source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBbekeUEEMZa"},"source":["# 옵티마이저 선언\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n","\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6TCWOHyEN0S"},"source":["# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnXaDxBh-G8G"},"source":["# model = torch.load('/content/drive/MyDrive/애쓰는 감자/data/minz_data/best_kobert_model_small.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["273710b949a44087845d1c56317d52c7","588132f4535d40d78b3b3d0912aadf78","659086d9dc5841468b967ff624d199ee","d3bf51b4ac424835947a7485169a2043","db374998a2ba4538b99011cd71414828","1456fff2e8e04852b169f33b09f77c63","57022b2abe59490c969e8ed19d07d9f7","c6a877e499924dc5b30f98e60594e67e"]},"id":"HuBtp2vAEPIB","executionInfo":{"status":"error","timestamp":1621657584907,"user_tz":-540,"elapsed":53769082,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"c1cc76ce-f006-4f0c-80e9-a5ebcd7921c8"},"source":["# 모델 학습 시작\n","for e in range(num_epochs):\n","    train_acc = 0.0\n","    val_acc = 0.0\n","    best_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","        if train_acc > best_acc:\n","          best_acc = train_acc\n","        torch.save(model, '/content/drive/MyDrive/애쓰는 감자/data/minz_data/best_kobert_model_se_001.pt')\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(val_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        val_acc += calc_accuracy(out, label)\n","    print(\"epoch {} val acc {}\".format(e+1, val_acc / (batch_id+1)))\n","\n","    torch.save(model, '/content/drive/MyDrive/애쓰는 감자/data/minz_data/last_kobert_model_se_001.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  import sys\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"273710b949a44087845d1c56317d52c7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=23391.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 batch id 1 loss 6.225164890289307 train acc 0.0\n","epoch 1 batch id 201 loss 6.1103196144104 train acc 0.003109452736318408\n","epoch 1 batch id 401 loss 5.95488977432251 train acc 0.01880714879467997\n","epoch 1 batch id 601 loss 5.531836032867432 train acc 0.02620632279534106\n","epoch 1 batch id 801 loss 5.248942852020264 train acc 0.0364128173116937\n","epoch 1 batch id 1001 loss 4.8514533042907715 train acc 0.04849317349317349\n","epoch 1 batch id 1201 loss 4.870554447174072 train acc 0.06300305301137943\n","epoch 1 batch id 1401 loss 4.893208026885986 train acc 0.08142993100166553\n","epoch 1 batch id 1601 loss 4.101771831512451 train acc 0.10079637726420992\n","epoch 1 batch id 1801 loss 3.5741307735443115 train acc 0.1190310938367573\n","epoch 1 batch id 2001 loss 4.709553241729736 train acc 0.136015325670498\n","epoch 1 batch id 2201 loss 3.803097724914551 train acc 0.15305542935029542\n","epoch 1 batch id 2401 loss 3.280712366104126 train acc 0.168974732750243\n","epoch 1 batch id 2601 loss 3.5171806812286377 train acc 0.18331090606177122\n","epoch 1 batch id 2801 loss 2.744774103164673 train acc 0.19765262406283465\n","epoch 1 batch id 3001 loss 2.9628450870513916 train acc 0.2110546484505162\n","epoch 1 batch id 3201 loss 3.2032101154327393 train acc 0.22267780901801504\n","epoch 1 batch id 3401 loss 3.1830894947052 train acc 0.2344531020288148\n","epoch 1 batch id 3601 loss 2.49057936668396 train acc 0.24584606127927427\n","epoch 1 batch id 3801 loss 2.808269739151001 train acc 0.25715820398140843\n","epoch 1 batch id 4001 loss 2.7357871532440186 train acc 0.2670061651253854\n","epoch 1 batch id 4201 loss 2.1270039081573486 train acc 0.2768289296199313\n","epoch 1 batch id 4401 loss 1.867875576019287 train acc 0.28584412633492373\n","epoch 1 batch id 4601 loss 1.406402587890625 train acc 0.294582699413171\n","epoch 1 batch id 4801 loss 1.3736244440078735 train acc 0.30213323613136145\n","epoch 1 batch id 5001 loss 2.6739275455474854 train acc 0.30982136905952123\n","epoch 1 batch id 5201 loss 1.7251280546188354 train acc 0.31709446901236904\n","epoch 1 batch id 5401 loss 2.2705681324005127 train acc 0.32399092760599846\n","epoch 1 batch id 5601 loss 2.282499313354492 train acc 0.33087841456882644\n","epoch 1 batch id 5801 loss 2.106659412384033 train acc 0.33726943630408507\n","epoch 1 batch id 6001 loss 2.0497922897338867 train acc 0.3428456368383045\n","epoch 1 batch id 6201 loss 1.921943187713623 train acc 0.34852577541256696\n","epoch 1 batch id 6401 loss 1.6640511751174927 train acc 0.3538314325886571\n","epoch 1 batch id 6601 loss 1.8078789710998535 train acc 0.3590554461445228\n","epoch 1 batch id 6801 loss 1.3995170593261719 train acc 0.36407023476939576\n","epoch 1 batch id 7001 loss 2.2323076725006104 train acc 0.36842951006998903\n","epoch 1 batch id 7201 loss 2.050870180130005 train acc 0.37279544507707135\n","epoch 1 batch id 7401 loss 2.392704725265503 train acc 0.3770549024906531\n","epoch 1 batch id 7601 loss 2.0363452434539795 train acc 0.3809531640573598\n","epoch 1 batch id 7801 loss 1.2016021013259888 train acc 0.38497201213519533\n","epoch 1 batch id 8001 loss 2.3944196701049805 train acc 0.388628504770236\n","epoch 1 batch id 8201 loss 1.7536239624023438 train acc 0.39247754338901664\n","epoch 1 batch id 8401 loss 1.302575707435608 train acc 0.3960837995476717\n","epoch 1 batch id 8601 loss 2.250999927520752 train acc 0.39951749796535196\n","epoch 1 batch id 8801 loss 1.3108664751052856 train acc 0.40274779381130854\n","epoch 1 batch id 9001 loss 1.4847321510314941 train acc 0.4058021330963216\n","epoch 1 batch id 9201 loss 2.040048360824585 train acc 0.4086557620548483\n","epoch 1 batch id 9401 loss 2.207082986831665 train acc 0.4112993298585249\n","epoch 1 batch id 9601 loss 1.962441325187683 train acc 0.41419296601048433\n","epoch 1 batch id 9801 loss 1.082152247428894 train acc 0.4168452198755227\n","epoch 1 batch id 10001 loss 1.1670857667922974 train acc 0.41946222044462217\n","epoch 1 batch id 10201 loss 1.9410651922225952 train acc 0.42232379178511886\n","epoch 1 batch id 10401 loss 2.1781582832336426 train acc 0.42472278306573114\n","epoch 1 batch id 10601 loss 2.2981579303741455 train acc 0.4273299688708618\n","epoch 1 batch id 10801 loss 2.3676600456237793 train acc 0.4297287288214053\n","epoch 1 batch id 11001 loss 1.9186674356460571 train acc 0.43210465715237983\n","epoch 1 batch id 11201 loss 1.7666276693344116 train acc 0.4342320626134571\n","epoch 1 batch id 11401 loss 1.8314064741134644 train acc 0.4364237055229068\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-59cfbbcd2144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/애쓰는 감자/data/minz_data/best_kobert_model_se_001.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch {} train acc {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 62592 vs 62470"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSrI3aToUwgp","executionInfo":{"status":"ok","timestamp":1621657591144,"user_tz":-540,"elapsed":776,"user":{"displayName":"곽민지","photoUrl":"","userId":"00094324617217372282"}},"outputId":"b7c2c8cc-ff5d-4eb2-9bd6-440a0fe2fef4"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat May 22 04:26:31 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P0    42W / 250W |   8883MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M9KYrkhilI22"},"source":[""]}]}