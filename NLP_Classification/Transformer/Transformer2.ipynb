{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer2.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZsWYX01IT2p","outputId":"869d6ef0-00b9-417e-abc1-9c361e0defd7"},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,  ReduceLROnPlateau\n","from tensorflow.keras.regularizers import *\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import *\n","import tensorflow.keras.backend as K\n","from datetime import datetime\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","import pickle\n","import gzip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n","\n","Enter your authorization code:\n","4/1AY0e-g5Dq9dMqGGvPGkk2dHDjKKqptOy3vDLqubJ9u0RVuDS92fjZRCEQM8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"naxZcydAIdWf"},"source":["with gzip.open('/content/gdrive/MyDrive/애쓰는 감자/data/preprocessing_data/del_X_train.pickle','rb') as f:\n","    del_X_train = pickle.load(f)\n","with gzip.open('/content/gdrive/MyDrive/애쓰는 감자/data/preprocessing_data/token_X_val.pickle','rb') as f:\n","    token_X_test = pickle.load(f)\n","with gzip.open('/content/gdrive/MyDrive/애쓰는 감자/data/preprocessing_data/del_y_train.pickle','rb') as f:\n","    del_y_train = pickle.load(f) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4RJ74K2I_5e"},"source":["max_len = 300\n","pad_X_train = pad_sequences(del_X_train, maxlen = max_len)\n","# pad_X_test = pad_sequences(token_X_test, maxlen = max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP4w9OFhMUKi"},"source":["with gzip.open('/content/gdrive/MyDrive/애쓰는 감자/data/preprocessing_data/pad_X_train.pickle', 'wb') as f:\n","    pickle.dump(pad_X_train, f)\n","# with gzip.open('/content/gdrive/MyDrive/애쓰는 감자/data/preprocessing_data/pad_X_val.pickle', 'wb') as f:\n","#     pickle.dump(pad_X_test, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87h5ccj7JDy3","executionInfo":{"status":"ok","timestamp":1620214085338,"user_tz":-540,"elapsed":227042,"user":{"displayName":"김영민","photoUrl":"","userId":"04915862517565535031"}},"outputId":"fc775ca8-5906-49bc-ccd4-3b8ceb795998"},"source":["pad_X_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0, ...,   2,   9,   7],\n","       [  0,   0,   0, ...,   2,   9,   7],\n","       [  0,   0,   0, ...,   2,   9,   7],\n","       ...,\n","       [  0,   0,   0, ...,  18,   1,   7],\n","       [  0,   0,   0, ...,   5,   2,   9],\n","       [  0,   0,   0, ..., 179, 453,  72]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"JFtsM1NEJOhy"},"source":["class MultiHeadAttention(Layer):\n","    def __init__(self, embedding_dim, num_heads=8):\n","        super(MultiHeadAttention, self).__init__()\n","        self.embedding_dim = embedding_dim # d_model\n","        self.num_heads = num_heads\n","\n","        assert embedding_dim % self.num_heads == 0\n","\n","        self.projection_dim = embedding_dim // num_heads\n","        self.query_dense = Dense(embedding_dim)\n","        self.key_dense = Dense(embedding_dim)\n","        self.value_dense = Dense(embedding_dim)\n","        self.dense = Dense(embedding_dim)\n","    \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            'embedding_dim' : self.embedding_dim,\n","            'num_heads' : self.num_heads,\n","            \n","            'projection_dim' : self.projection_dim,\n","            'query_dense' : self.query_dense,\n","            'key_dense' : self.key_dense,\n","            'value_dense' : self.value_dense,\n","            'dense' : self.dense\n","        })\n","\n","    def scaled_dot_product_attention(self, query, key, value):\n","        matmul_qk = tf.matmul(query, key, transpose_b=True)\n","        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","        logits = matmul_qk / tf.math.sqrt(depth)\n","        attention_weights = tf.nn.softmax(logits, axis=-1)\n","        output = tf.matmul(attention_weights, value)\n","        return output, attention_weights\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        # x.shape = [batch_size, seq_len, embedding_dim]\n","        batch_size = tf.shape(inputs)[0]\n","\n","        # (batch_size, seq_len, embedding_dim)\n","        query = self.query_dense(inputs)\n","        key = self.key_dense(inputs)\n","        value = self.value_dense(inputs)\n","\n","        # (batch_size, num_heads, seq_len, projection_dim)\n","        query = self.split_heads(query, batch_size)  \n","        key = self.split_heads(key, batch_size)\n","        value = self.split_heads(value, batch_size)\n","\n","        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n","        # (batch_size, seq_len, num_heads, projection_dim)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n","\n","        # (batch_size, seq_len, embedding_dim)\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n","        outputs = self.dense(concat_attention)\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YGmQxSgJPYS"},"source":["class TransformerBlock(Layer):\n","    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = MultiHeadAttention(embedding_dim, num_heads)\n","        self.ffn = Sequential(\n","            [Dense(dff, activation=\"relu\"),\n","             Dense(embedding_dim),]\n","        )\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            'att' : self.att,\n","            'ffn' : self.ffn,\n","            'layernorm1' : self.layernorm1,\n","            'layernorm2' : self.layernorm2,\n","            'dropout1' : self.dropout1,\n","            'dropout2' : self.dropout2\n","        })\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zk6eojbdJRFL"},"source":["class TokenAndPositionEmbedding(Layer):\n","    def __init__(self, max_len, vocab_size, embedding_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = Embedding(vocab_size, embedding_dim)\n","        self.pos_emb = Embedding(max_len, embedding_dim)\n","        \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            'token_emb' : self.token_emb,\n","            'pos_emb' : self.pos_emb,\n","        })\n","        return config\n","\n","    def call(self, x):\n","        max_len = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=max_len, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nY9NiOcJap8"},"source":["embedding_dim = 32  # Embedding size for each token\n","num_heads = 4  # Number of attention heads\n","dff = 32  # Hidden layer size in feed forward network inside transformer\n","vocab_size = 18658 # Transformer1에 있음\n","inputs = Input(shape=(max_len,))\n","embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n","x = transformer_block(x)\n","x = GlobalAveragePooling1D()(x)\n","x = Dropout(0.1)(x)\n","x = Dense(100, activation=\"relu\")(x)\n","x = Dropout(0.1)(x)\n","outputs = Dense(79, activation=\"softmax\")(x)\n","\n","model = Model(inputs=inputs, outputs=outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REErYlEfNhfu","executionInfo":{"status":"ok","timestamp":1620196180918,"user_tz":-540,"elapsed":841,"user":{"displayName":"김영민","photoUrl":"","userId":"04915862517565535031"}},"outputId":"df5a06df-52fb-49fa-aaf8-31f78cc84725"},"source":["len(del_y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1139566"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9XsvfN2N8sf","executionInfo":{"status":"ok","timestamp":1620196640329,"user_tz":-540,"elapsed":884,"user":{"displayName":"김영민","photoUrl":"","userId":"04915862517565535031"}},"outputId":"ea7b5998-2436-499b-e019-f57ce3a2cea4"},"source":["len(del_y_train[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["79"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"dO-7Gk_vJdI9"},"source":["import os\n","path = '/content/gdrive/MyDrive/애쓰는 감자/코드/kym/'\n","ckpt_1 = 'Transformer.ckpt'\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","mc = ModelCheckpoint(filepath =  os.path.join(path, ckpt_1), monitor = 'val_accuracy', save_best_only = True, mode = 'max',verbose = 1, save_weights_only=True)\n","es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience = 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftGcQRTlJz4D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620224560421,"user_tz":-540,"elapsed":10173889,"user":{"displayName":"김영민","photoUrl":"","userId":"04915862517565535031"}},"outputId":"c57e3dad-8ba1-48c7-95eb-9e8676dbc565"},"source":["history = model.fit(pad_X_train, del_y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks = [mc,es])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","14245/14245 [==============================] - 873s 61ms/step - loss: 1.3148 - accuracy: 0.6437 - val_loss: 1.1445 - val_accuracy: 0.6828\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.68281, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 2/100\n","14245/14245 [==============================] - 869s 61ms/step - loss: 1.1425 - accuracy: 0.6867 - val_loss: 1.0789 - val_accuracy: 0.6988\n","\n","Epoch 00002: val_accuracy improved from 0.68281 to 0.69875, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 3/100\n","14245/14245 [==============================] - 781s 55ms/step - loss: 1.0825 - accuracy: 0.7017 - val_loss: 1.0477 - val_accuracy: 0.7079\n","\n","Epoch 00003: val_accuracy improved from 0.69875 to 0.70792, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 4/100\n","14245/14245 [==============================] - 716s 50ms/step - loss: 1.0441 - accuracy: 0.7106 - val_loss: 1.0287 - val_accuracy: 0.7129\n","\n","Epoch 00004: val_accuracy improved from 0.70792 to 0.71287, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 5/100\n","14245/14245 [==============================] - 726s 51ms/step - loss: 1.0169 - accuracy: 0.7169 - val_loss: 1.0237 - val_accuracy: 0.7138\n","\n","Epoch 00005: val_accuracy improved from 0.71287 to 0.71384, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 6/100\n","14245/14245 [==============================] - 795s 56ms/step - loss: 0.9951 - accuracy: 0.7222 - val_loss: 1.0200 - val_accuracy: 0.7170\n","\n","Epoch 00006: val_accuracy improved from 0.71384 to 0.71698, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 7/100\n","14245/14245 [==============================] - 828s 58ms/step - loss: 0.9790 - accuracy: 0.7261 - val_loss: 1.0213 - val_accuracy: 0.7176\n","\n","Epoch 00007: val_accuracy improved from 0.71698 to 0.71762, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 8/100\n","14245/14245 [==============================] - 836s 59ms/step - loss: 0.9645 - accuracy: 0.7298 - val_loss: 1.0232 - val_accuracy: 0.7174\n","\n","Epoch 00008: val_accuracy did not improve from 0.71762\n","Epoch 9/100\n","14245/14245 [==============================] - 720s 51ms/step - loss: 0.9521 - accuracy: 0.7325 - val_loss: 1.0223 - val_accuracy: 0.7183\n","\n","Epoch 00009: val_accuracy improved from 0.71762 to 0.71833, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 10/100\n","14245/14245 [==============================] - 726s 51ms/step - loss: 0.9419 - accuracy: 0.7352 - val_loss: 1.0326 - val_accuracy: 0.7186\n","\n","Epoch 00010: val_accuracy improved from 0.71833 to 0.71856, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 11/100\n","14245/14245 [==============================] - 856s 60ms/step - loss: 0.9331 - accuracy: 0.7374 - val_loss: 1.0366 - val_accuracy: 0.7192\n","\n","Epoch 00011: val_accuracy improved from 0.71856 to 0.71918, saving model to /content/gdrive/MyDrive/애쓰는 감자/코드/kym/Transformer.ckpt\n","Epoch 12/100\n","14245/14245 [==============================] - 721s 51ms/step - loss: 0.9241 - accuracy: 0.7391 - val_loss: 1.0279 - val_accuracy: 0.7183\n","\n","Epoch 00012: val_accuracy did not improve from 0.71918\n","Epoch 13/100\n","14245/14245 [==============================] - 722s 51ms/step - loss: 0.9163 - accuracy: 0.7412 - val_loss: 1.0455 - val_accuracy: 0.7176\n","\n","Epoch 00013: val_accuracy did not improve from 0.71918\n","Epoch 00013: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7SEEEwBzxHz","executionInfo":{"status":"ok","timestamp":1620225901476,"user_tz":-540,"elapsed":6468,"user":{"displayName":"김영민","photoUrl":"","userId":"04915862517565535031"}},"outputId":"8a2e65da-5818-4547-b4a9-b4539f490fd6"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["507637"]},"metadata":{"tags":[]},"execution_count":16}]}]}