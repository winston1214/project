{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "#import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "#from google.colab import output\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(inputs):\n",
    "    noise = torch.randn_like(inputs)\n",
    "    \n",
    "    return inputs + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(D.Dataset):\n",
    "    \"\"\"\n",
    "    path = {BASE_PATH,DATA_DIR1, DATA_DIR2 ,CSV_PATH}\n",
    "    Return: pytorch custome dataset format \n",
    "    \"\"\"\n",
    "    def __init__(self, path, data, label, transform=None):\n",
    "        self.path = path\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "#         self.diagonal_reverse = diagonal_reverse\n",
    "#         self.add_noise = add_noise\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.path + self.data[idx])\n",
    "        label = self.label[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "#             image = self.diagonal_reverse(image)\n",
    "#             image = add_noise(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_model(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(My_model, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\n",
    "        #self.pretrained = models.resnet50()\n",
    "        \n",
    "        self.pretrained = pretrained\n",
    "        self.FC = nn.Linear(1000, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # resnet의 입력은 [3, N, N]으로\n",
    "        # 3개의 채널을 갖기 때문에\n",
    "        # resnet 입력 전에 conv2d를 한 층 추가\n",
    "        x = F.relu(self.conv2d(x))\n",
    "\n",
    "        \n",
    "        x = F.relu(self.pretrained(x))\n",
    "\n",
    "        # 마지막 출력에 nn.Linear를 추가\n",
    "        # multilabel을 예측해야 하기 때문에\n",
    "        # softmax가 아닌 sigmoid를 적용\n",
    "        x = torch.sigmoid(self.FC(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(state, SAVE_DIR, epoch, model, optimizer):\n",
    "    with open(SAVE_DIR + state +\".path.tar\", \"wb\") as f:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()},\n",
    "            f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'D:/dacon/2nd/'\n",
    "namelist = os.listdir(base_path + 'dirty_mnist_2nd/')\n",
    "# namelist = os.listdir(base_path)\n",
    "labels = pd.read_csv(base_path + \"dirty_mnist_2nd_answer.csv\").to_numpy()[:, 1:]\n",
    "\n",
    "save_dir = './save_file/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = A.Compose([\n",
    "#     A.RandomCrop(width=128, height=128),\n",
    "#     A.HorizontalFlip(p=1),\n",
    "#     A.CenterCrop(height=128, width=128),\n",
    "#     A.Rotate(),\n",
    "#     A.Cutout(\n",
    "#     num_holes=10,\n",
    "#     max_h_size=20,\n",
    "#     max_w_size=20,\n",
    "#     fill_value=0,\n",
    "#     always_apply=True,\n",
    "#     p=0.5,)\n",
    "# ])\n",
    "\n",
    "# test_transforms = A.Compose([\n",
    "#     A.RandomCrop(width=128, height=128),\n",
    "#     A.HorizontalFlip(p=1),\n",
    "#     A.CenterCrop(height=128, width=128),\n",
    "#     A.Rotate(),\n",
    "#     A.Cutout(\n",
    "#     num_holes=10,\n",
    "#     max_h_size=20,\n",
    "#     max_w_size=20,\n",
    "#     fill_value=0,\n",
    "#     always_apply=True,\n",
    "#     p=0.5,)\n",
    "# ])\n",
    "\n",
    "# # train_dataset = aug_random_imshow(train_img_paths, transformer)\n",
    "# # aug_random_imshow(val_img_paths, transformer)\n",
    "\n",
    "# dataset = CustomDataset(base_path+'dirty_mnist_2nd/', namelist, labels, transformer)\n",
    "\n",
    "# train_dataset, val_dataset = D.random_split(dataset, [len(dataset) - int(len(dataset) * 0.1), int(len(dataset) * 0.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = T.Compose([\n",
    "#     T.RandomCrop(128,128),\n",
    "#     T.RandomRotation(2.8),\n",
    "#     T.RandomHorizontalFlip(),\n",
    "#     T.CenterCrop(10),\n",
    "#     T.RandomVerticalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.1307,), (0.3081,)),\n",
    "    T.RandomRotation(60, expand=False),\n",
    "    T.RandomAffine(30)\n",
    "    #AddGaussianNoise(0., 1.)\n",
    "])\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.1307,), (0.3081,)),\n",
    "    T.RandomRotation(60, expand=False),\n",
    "    T.RandomAffine(30)\n",
    "    #AddGaussianNoise(0., 1.)\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(base_path+'dirty_mnist_2nd/', namelist, labels, transformer)\n",
    "train_dataset, val_dataset = D.random_split(dataset, [len(dataset) - int(len(dataset) * 0.1), int(len(dataset) * 0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_dataloader =  torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "# 모델 선언\n",
    "pretrained = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "b4_model = My_model(pretrained)\n",
    "model = nn.DataParallel(b4_model)\n",
    "model.to(device)# gpu에 모델 할당\n",
    "\n",
    "# 훈련 옵션 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "#                                             step_size = 10,\n",
    "#                                             gamma = 0.85)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=0.1,eta_min=0.0001)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [10:10,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1875/1875], Loss: 0.6854681624094645, Acc 0.5397538461538461\n",
      "Validation acc: 0.5412275024654832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1216it [06:34,  3.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-30dfbc6fde32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprobs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 훈련 시작\n",
    "total_step = len(train_dataloader)\n",
    "best_val_acc = 0\n",
    "EPOCH = 50\n",
    "for epoch in range(EPOCH):\n",
    "    train_acc_list = []\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, (images, labels) in tqdm(enumerate(train_dataloader)):\n",
    "        images = images.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        probs= model(images)\n",
    "        loss = criterion(probs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        probs  = probs.cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        preds = probs > 0.75\n",
    "        batch_acc = (labels == preds).mean()\n",
    "        train_acc_list.append(batch_acc)\n",
    "    \n",
    "    train_acc = np.mean(train_acc_list)\n",
    "    print(f'Epoch [{epoch+1}/{EPOCH}], Step [{i+1}/{total_step}], Loss: {running_loss/total_step}, Acc {train_acc}')\n",
    "\n",
    "    model.eval()\n",
    "    valid_acc_list = []\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.type(torch.FloatTensor).to(device)\n",
    "            labels = labels.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            probs = model(images)\n",
    "            valid_loss = criterion(probs, labels)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            preds = probs > 0.75\n",
    "            batch_acc = (labels == preds).mean()\n",
    "            valid_acc_list.append(batch_acc)\n",
    "            \n",
    "        val_acc = np.mean(valid_acc_list)\n",
    "        print(f'Validation acc: {val_acc}')\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        save('best', save_dir, epoch, model, optimizer)\n",
    "    save('last', save_dir, epoch, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_namelist = os.listdir(base_path + 'test_dirty_mnist_2nd/')\n",
    "test_labels = pd.read_csv(base_path + \"sample_submission.csv\").to_numpy()[:, 1:]\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.1307,), (0.3081,)),\n",
    "    T.RandomRotation(60, expand=False),\n",
    "    T.RandomAffine(30)\n",
    "    #AddGaussianNoise(0., 1.)\n",
    "])\n",
    "\n",
    "test_dataset = CustomDataset(base_path+'/test_dirty_mnist_2nd/', test_namelist, test_labels, test_transforms)\n",
    "test_dataloader =  torch.utils.data.DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('save_file/best.path.tar'))\n",
    "model.eval()\n",
    "prediction_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images = images.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        probs = model(images)\n",
    "        \n",
    "        probs = probs.cpu().detach().numpy()\n",
    "        preds = probs > 0.75\n",
    "        prediction_list.append(preds[0].astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'eff_epoch50_batch24_Rotate_Affine_dead'\n",
    "\n",
    "test_labels_DF = pd.read_csv(base_path + \"sample_submission.csv\")\n",
    "test_labels_DF.iloc[:, 1:] = prediction_list\n",
    "test_labels_DF.to_csv(file_name +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
